{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "564a44a7-95cb-40a4-a2d7-1eaf2e456811",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is THE model.\n",
    "\n",
    "It combines improvements from the LLAMA3 series, with others from Gemma2.\n",
    "It has:\n",
    "- GQA\n",
    "- GeGLU (thinking to maybe use SwiGLU or ReGLU)\n",
    "- RoPE\n",
    "\n",
    "I still would need to implement KV-caching to improve inference type.\n",
    "\"\"\"\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "import inspect\n",
    "\n",
    "def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\n",
    "    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)\n",
    "    \"\"\"\n",
    "    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
    "    if n_rep == 1:\n",
    "        return hidden_states\n",
    "    hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
    "    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "class CausalSelfAttentionGQA(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "\n",
    "        self.head_dim = config.n_embd // config.n_head\n",
    "        self.n_kv_heads = config.n_kv_heads # Nombre de grups de query\n",
    "        self.n_head = config.n_head\n",
    "\n",
    "        shape = (config.n_head + 2 * config.n_kv_heads) * self.head_dim\n",
    "\n",
    "        self.wq = nn.Linear(config.n_embd, config.n_head * self.head_dim, bias=False )\n",
    "        self.wk = nn.Linear(config.n_embd, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(config.n_embd, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(config.n_head * self.head_dim, config.n_embd, bias=False)\n",
    "        self.cache = None\n",
    "        self.queries_per_kv = self.n_head // self.n_kv_heads\n",
    "\n",
    "    def forward(self, x, freqs_cis, mask, return_attention=False):\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "        xq = xq.view(B, T, self.n_head, self.head_dim)\n",
    "        xk = xk.view(B, T, self.n_kv_heads, self.head_dim)\n",
    "        xv = xv.view(B, T, self.n_kv_heads, self.head_dim)\n",
    "\n",
    "        xq = apply_rope(xq, freqs_cis)\n",
    "        xk = apply_rope(xk, freqs_cis)\n",
    "\n",
    "        xk = repeat_kv(xk, self.queries_per_kv)\n",
    "        xv = repeat_kv(xv, self.queries_per_kv)\n",
    "        print(\"aquí si\")\n",
    "        \n",
    "        xq, xk, xv = (x.transpose(1, 2) for x in (xq, xk, xv))\n",
    "\n",
    "        scores = torch.matmul(xq, xk.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask  # (bs, n_local_heads, seqlen, cache_len + seqlen)\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, xv)\n",
    "\n",
    "        output = output.transpose(1, 2).contiguous().view(B, T, -1)\n",
    "        # output projection\n",
    "        proj = self.wo(output)\n",
    "        if return_attention:\n",
    "            return proj, scores\n",
    "        return proj\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rope(q, k, cos, sin, unsqueeze_dim=1):\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed\n",
    "\n",
    "\n",
    "class CausalSelfAttentionGQA(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "\n",
    "        self.config = config\n",
    "        self.num_heads = config.n_head\n",
    "        self.num_kv_heads = config.n_kv_heads\n",
    "        self.head_dim = config.n_embd // self.num_heads\n",
    "        self.num_kv_groups = self.num_heads // self.num_kv_heads\n",
    "        \n",
    "\n",
    "        self.q_proj = nn.Linear(config.n_embd, self.num_heads * self.head_dim, bias=False)\n",
    "        self.k_proj = nn.Linear(config.n_embd, self.num_kv_heads * self.head_dim, bias=False)\n",
    "        self.v_proj = nn.Linear(config.n_embd, self.num_kv_heads * self.head_dim, bias=False)\n",
    "        self.o_proj = nn.Linear(self.num_heads * self.head_dim, config.n_embd, bias=False)\n",
    "\n",
    "\n",
    "        #self.sliding_window_size = config.sliding_window_size\n",
    "        self.max_seq_len = config.block_size\n",
    "\n",
    "    def forward(self, x, cos_sin: tuple, return_attention = None):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "\n",
    "        q = q.view(B, T, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        k = k.view(B, T, self.num_kv_heads, self.head_dim).transpose(1,2)\n",
    "        v = v.view(B, T, self.num_kv_heads, self.head_dim).transpose(1,2)\n",
    "\n",
    "        cos, sin = cos_sin\n",
    "        q, k = apply_rope(q, k, cos, sin)\n",
    "\n",
    "        k = repeat_kv(k, self.num_kv_groups)\n",
    "        v = repeat_kv(v, self.num_kv_groups)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(2,3)) / math.sqrt(self.head_dim)\n",
    "\n",
    "        mask = True\n",
    "        if mask is not None:  # the mask is not correct, it needs to be [B, C, T, T]\n",
    "            mask = torch.full((T, T), float(\"-inf\"), device=x.device)\n",
    "            mask = torch.triu(mask, diagonal=1)\n",
    "            mask = mask.unsqueeze(0).unsqueeze(1)\n",
    "            scores = scores + mask\n",
    "\n",
    "        scores = nn.functional.softmax(scores, dim=-1, dtype=torch.float32).to(q.dtype)\n",
    "        output = torch.matmul(scores, v)\n",
    "\n",
    "        if output.size() != (B, self.num_heads, T, self.head_dim):\n",
    "            raise ValueError(f\"ALGO HA ANAT MALAMENT, output té dimensions {output.size()}\")\n",
    "        \n",
    "        output = output.transpose(1,2).contiguous()\n",
    "        output = output.reshape(B, T, -1)\n",
    "\n",
    "        output = self.o_proj(output)\n",
    "\n",
    "        if return_attention:\n",
    "            return output, scores\n",
    "        return output, None\n",
    "        \n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, d, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(d)) # weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_dtype = x.dtype\n",
    "        x = x.to(torch.float32)\n",
    "        variance = x.pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = x * torch.rsqrt(variance + self.eps)\n",
    "        return self.weight * hidden_states.to(input_dtype)\n",
    "\n",
    "\n",
    "def compute_rope_default(config, device):\n",
    "    base = config.rope_theta\n",
    "    dim = config.n_embd // config.n_head\n",
    "\n",
    "    inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.int64).float().to(device)/dim))\n",
    "    return inv_freq, 1.0\n",
    "\n",
    "\n",
    "\n",
    "class LlamaRotaryEmbedding(nn.Module):\n",
    "    def __init__(self, config, device = None):\n",
    "        super().__init__()\n",
    "        self.max_position_embeddings = config.max_position_embeddings\n",
    "        self.factor = config.scaling_factor\n",
    "        self.base = config.rope_theta\n",
    "        self.dim = config.n_embd // config.n_head\n",
    "        self.config = config\n",
    "        self.rope_init_fn = compute_rope_default\n",
    "\n",
    "        inv_freq, self.attention_scaling = self.rope_init_fn(self.config, device)\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "        self.original_inv_freq = self.inv_freq\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x, position_ids):\n",
    "        inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
    "        position_ids_expanded = position_ids[:, None, :].float()\n",
    "        device_type = x.device.type\n",
    "        device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
    "        with torch.autocast(device_type=device_type, enabled=False):\n",
    "            freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1)\n",
    "            cos = emb.cos()\n",
    "            sin = emb.sin()\n",
    "\n",
    "        # Advanced RoPE types (e.g. yarn) apply a post-processing scaling factor, equivalent to scaling attention\n",
    "        cos = cos * self.attention_scaling\n",
    "        sin = sin * self.attention_scaling\n",
    "\n",
    "        return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
    "\n",
    "        \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    class GeGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gate = x.chunk(2, dim=-1)\n",
    "        # Silu és el mateix que swift function\n",
    "        return F.gelu(gate) * x\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.gate_proj   = nn.Linear(config.n_embd, config.intermediate_size, bias=False) # gate_proj\n",
    "        self.down_proj = nn.Linear(config.intermediate_size, config.n_embd, bias=False) # down proj\n",
    "        self.up_proj = nn.Linear(config.n_embd, config.intermediate_size, bias=False) # up proj\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.down_proj(F.gelu(self.gate_proj(x), approximate=\"tanh\")* self.up_proj(x)) \n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.input_layernorm = RMSNorm(config.n_embd, config.norm_eps) # input_layernorm\n",
    "        self.self_attn = CausalSelfAttentionGQA(config)\n",
    "        self.post_attention_layernorm = RMSNorm(config.n_embd, config.norm_eps) # post_attention_layernorm\n",
    "        self.mlp = MLP(config)\n",
    "    \n",
    "    def forward(self, x, cos_sin):\n",
    "        residual = x\n",
    "        x = self.input_layernorm(x)\n",
    "        x, attn_weights = self.self_attn(x, cos_sin)\n",
    "\n",
    "        x = residual + x\n",
    "\n",
    "        residual = x\n",
    "        x = self.post_attention_layernorm(x)\n",
    "        x = self.mlp(x)\n",
    "        x = residual + x\n",
    "\n",
    "        return x\n",
    "\n",
    "class Aloja(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "        self.padding_idx = config.pad_token_id\n",
    "        self.embed_tokens =nn.Embedding(config.vocab_size, config.n_embd, self.padding_idx)\n",
    "\n",
    "        self.layers = nn.ModuleList([Block(config) for i in range(config.n_layer)])\n",
    "\n",
    "        self.norm =  RMSNorm(config.n_embd, config.norm_eps)\n",
    "        self.rotary_emb = LlamaRotaryEmbedding(config=config)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        self.embed_tokens.weight = self.lm_head.weight # Linkeddddd\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is smaller\"\n",
    "\n",
    "        x = self.embed_tokens(idx)\n",
    "\n",
    "\n",
    "        position_ids = torch.arange(T, device = x.device).unsqueeze(0)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        cos_sin = self.rotary_emb(x, position_ids)\n",
    "\n",
    "        for block in self.layers:\n",
    "            x = block(x, cos_sin)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "\n",
    "        logits = self.lm_head(x).float()\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def configure_optimizers(self, learning_rate, weight_decay=0.1, betas=(0.9, 0.95), device_type='cuda'):\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == \"cuda\"\n",
    "        print(f\"using fused AdamW: {use_fused}\")\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, eps=1e-8, fused=use_fused)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AlojaConfig:\n",
    "    block_size: int = 128\n",
    "    vocab_size: int = 500\n",
    "    n_layer: int = 2\n",
    "    n_head: int = 2\n",
    "    n_embd: int = 192 # hidden_size\n",
    "    intermediate_size = 128 # 3072\n",
    "    n_kv_heads: int = 1 # nombre de grups de query\n",
    "    norm_eps: int = 1e-05\n",
    "    rope_theta: float = 10000.0\n",
    "    use_scaled_rope: bool = False\n",
    "    scaling_factor: int = 1\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len:int = 128\n",
    "    max_position_embeddings:int = 128\n",
    "    pad_token_id:int = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a2a6d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = AlojaConfig()\n",
    "\n",
    "model = Aloja(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9c665e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full definition of a GPT Language Model, all of it in this single file.\n",
    "References:\n",
    "1) the official GPT-2 TensorFlow implementation released by OpenAI:\n",
    "https://github.com/openai/gpt-2/blob/master/src/model.py\n",
    "2) huggingface/transformers PyTorch implementation:\n",
    "https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "        self.flash = False\n",
    "        if not self.flash:\n",
    "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
    "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                        .view(1, 1, config.block_size, config.block_size))\n",
    "        \n",
    "\n",
    "    def forward(self, x, return_attention = False):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        if self.flash:\n",
    "            # efficient attention using Flash Attention CUDA kernels\n",
    "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
    "        else:\n",
    "            # manual implementation of attention\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        if return_attention:\n",
    "            return y, att\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 128\n",
    "    vocab_size: int = 500 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 2\n",
    "    n_head: int = 2\n",
    "    n_embd: int = 192\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = False # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        # with weight tying when using torch.compile() some warnings get generated:\n",
    "        # \"UserWarning: functional_call was passed multiple values for tied weights.\n",
    "        # This behavior is deprecated and will be an error in future versions\"\n",
    "        # not 100% sure what this is, so far seems to be harmless. TODO investigate\n",
    "        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
    "\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        if non_embedding:\n",
    "            n_params -= self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def crop_block_size(self, block_size):\n",
    "        # model surgery to decrease the block size if necessary\n",
    "        # e.g. we may load the GPT2 pretrained model checkpoint (block size 1024)\n",
    "        # but want to use a smaller block size for some smaller, simpler model\n",
    "        assert block_size <= self.config.block_size\n",
    "        self.config.block_size = block_size\n",
    "        self.transformer.wpe.weight = nn.Parameter(self.transformer.wpe.weight[:block_size])\n",
    "        for block in self.transformer.h:\n",
    "            if hasattr(block.attn, 'bias'):\n",
    "                block.attn.bias = block.attn.bias[:,:,:block_size,:block_size]\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type, override_args=None):\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        override_args = override_args or {} # default to empty dict\n",
    "        # only dropout can be overridden see more notes below\n",
    "        assert all(k == 'dropout' for k in override_args)\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        print(\"forcing vocab_size=50257, block_size=1024, bias=True\")\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        config_args['bias'] = True # always True for GPT model checkpoints\n",
    "        # we can override the dropout rate, if desired\n",
    "        if 'dropout' in override_args:\n",
    "            print(f\"overriding dropout rate to {override_args['dropout']}\")\n",
    "            config_args['dropout'] = override_args['dropout']\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
    "        # start with all of the candidate parameters\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        # filter out those that do not require grad\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == 'cuda'\n",
    "        extra_args = dict(fused=True) if use_fused else dict()\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
    "        print(f\"using fused AdamW: {use_fused}\")\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def estimate_mfu(self, fwdbwd_per_iter, dt):\n",
    "        \"\"\" estimate model flops utilization (MFU) in units of A100 bfloat16 peak FLOPS \"\"\"\n",
    "        # first estimate the number of flops we do per iteration.\n",
    "        # see PaLM paper Appendix B as ref: https://arxiv.org/abs/2204.02311\n",
    "        N = self.get_num_params()\n",
    "        cfg = self.config\n",
    "        L, H, Q, T = cfg.n_layer, cfg.n_head, cfg.n_embd//cfg.n_head, cfg.block_size\n",
    "        flops_per_token = 6*N + 12*L*H*Q*T\n",
    "        flops_per_fwdbwd = flops_per_token * T\n",
    "        flops_per_iter = flops_per_fwdbwd * fwdbwd_per_iter\n",
    "        # express our flops throughput as ratio of A100 bfloat16 peak flops\n",
    "        flops_achieved = flops_per_iter * (1.0/dt) # per second\n",
    "        flops_promised = 312e12 # A100 GPU bfloat16 peak flops is 312 TFLOPS\n",
    "        mfu = flops_achieved / flops_promised\n",
    "        return mfu\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            # forward the model to get the logits for the index in the sequence\n",
    "            logits, _ = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "eb4418da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "number of parameters: 0.98M\n"
     ]
    }
   ],
   "source": [
    "model_config2 = GPTConfig()\n",
    "model2 = GPT(model_config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "93d6f7bd-07af-43e5-a573-af102a4de2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "Total desired batach size: 1024\n",
      "Calculated gradient accumulation steps: 4\n",
      "Shards: ['./data/patufet-mini\\\\patufet_train_000001', './data/patufet-mini\\\\patufet_train_000002', './data/patufet-mini\\\\patufet_train_000003']\n",
      "found 3 shards for split train\n",
      "Shards: ['./data/patufet-mini\\\\patufet_val_000000']\n",
      "found 1 shards for split val\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "number of parameters: 0.98M\n",
      "num decayed parameter tensors: 10, with 1,005,312 parameters\n",
      "num non-decayed parameter tensors: 5, with 960 parameters\n",
      "using fused AdamW: False\n",
      "step    0, loss: 6.258945, norm: 1.9119, dt: 226.04ms, tok/sec: 4530.13\n",
      "step    1, loss: 6.116513, norm: 1.7941, dt: 252.70ms, tok/sec: 4052.31\n",
      "step    2, loss: 5.844625, norm: 1.3013, dt: 215.49ms, tok/sec: 4752.04\n",
      "step    3, loss: 5.700125, norm: 1.3333, dt: 211.39ms, tok/sec: 4844.22\n",
      "step    4, loss: 5.471749, norm: 1.6726, dt: 213.07ms, tok/sec: 4805.94\n",
      "step    5, loss: 5.590451, norm: 9.1753, dt: 182.20ms, tok/sec: 5620.20\n",
      "step    6, loss: 5.027242, norm: 1.5857, dt: 200.43ms, tok/sec: 5108.93\n",
      "step    7, loss: 5.005247, norm: 3.7490, dt: 218.20ms, tok/sec: 4693.01\n",
      "step    8, loss: 4.723498, norm: 1.6377, dt: 236.63ms, tok/sec: 4327.43\n",
      "step    9, loss: 4.609219, norm: 1.9757, dt: 202.02ms, tok/sec: 5068.91\n",
      "step   10, loss: 4.410719, norm: 1.9261, dt: 198.99ms, tok/sec: 5146.02\n",
      "step   11, loss: 4.277079, norm: 1.8535, dt: 200.17ms, tok/sec: 5115.55\n",
      "step   12, loss: 4.501406, norm: 6.6765, dt: 169.09ms, tok/sec: 6055.78\n",
      "step   13, loss: 3.846514, norm: 1.4115, dt: 178.56ms, tok/sec: 5734.64\n",
      "step   14, loss: 4.102368, norm: 1.3775, dt: 170.37ms, tok/sec: 6010.44\n",
      "step   15, loss: 3.536977, norm: 1.8553, dt: 166.67ms, tok/sec: 6143.73\n",
      "step   16, loss: 3.678543, norm: 1.3953, dt: 149.94ms, tok/sec: 6829.54\n",
      "step   17, loss: 3.367893, norm: 1.6661, dt: 212.60ms, tok/sec: 4816.54\n",
      "step   18, loss: 3.203053, norm: 1.1593, dt: 158.61ms, tok/sec: 6456.06\n",
      "step   19, loss: 3.143322, norm: 1.3579, dt: 166.66ms, tok/sec: 6144.30\n",
      "step   20, loss: 2.818654, norm: 1.0688, dt: 193.48ms, tok/sec: 5292.59\n",
      "step   21, loss: 2.897084, norm: 1.1802, dt: 161.96ms, tok/sec: 6322.67\n",
      "step   22, loss: 2.487474, norm: 1.2943, dt: 194.86ms, tok/sec: 5255.12\n",
      "step   23, loss: 2.530450, norm: 1.1734, dt: 164.42ms, tok/sec: 6227.78\n",
      "step   24, loss: 2.262900, norm: 1.7676, dt: 164.67ms, tok/sec: 6218.39\n",
      "step   25, loss: 2.132623, norm: 1.2513, dt: 186.26ms, tok/sec: 5497.64\n",
      "step   26, loss: 2.072770, norm: 1.3241, dt: 161.05ms, tok/sec: 6358.46\n",
      "step   27, loss: 1.781706, norm: 1.2688, dt: 172.76ms, tok/sec: 5927.44\n",
      "step   28, loss: 1.772192, norm: 1.2585, dt: 188.09ms, tok/sec: 5444.20\n",
      "step   29, loss: 1.516216, norm: 1.2168, dt: 161.54ms, tok/sec: 6339.15\n",
      "step   30, loss: 1.476758, norm: 1.4069, dt: 183.13ms, tok/sec: 5591.63\n",
      "step   31, loss: 1.258270, norm: 1.2203, dt: 158.45ms, tok/sec: 6462.48\n",
      "step   32, loss: 1.176626, norm: 1.5067, dt: 174.20ms, tok/sec: 5878.36\n",
      "step   33, loss: 1.052637, norm: 1.3589, dt: 168.21ms, tok/sec: 6087.50\n",
      "step   34, loss: 0.920575, norm: 1.4980, dt: 145.57ms, tok/sec: 7034.48\n",
      "step   35, loss: 0.867152, norm: 1.2944, dt: 258.48ms, tok/sec: 3961.58\n",
      "step   36, loss: 0.685546, norm: 1.2124, dt: 153.56ms, tok/sec: 6668.40\n",
      "step   37, loss: 0.645411, norm: 1.1753, dt: 195.83ms, tok/sec: 5229.09\n",
      "step   38, loss: 0.513008, norm: 1.0774, dt: 179.71ms, tok/sec: 5698.12\n",
      "step   39, loss: 0.467675, norm: 1.0156, dt: 207.55ms, tok/sec: 4933.75\n",
      "step   40, loss: 0.369174, norm: 0.8488, dt: 163.40ms, tok/sec: 6266.98\n",
      "step   41, loss: 0.356077, norm: 1.1771, dt: 187.26ms, tok/sec: 5468.21\n",
      "step   42, loss: 0.268325, norm: 0.7919, dt: 181.23ms, tok/sec: 5650.14\n",
      "step   43, loss: 0.261557, norm: 1.3831, dt: 177.29ms, tok/sec: 5775.79\n",
      "step   44, loss: 0.200680, norm: 0.7606, dt: 159.93ms, tok/sec: 6402.86\n",
      "step   45, loss: 0.194145, norm: 0.7893, dt: 182.55ms, tok/sec: 5609.28\n",
      "step   46, loss: 0.128137, norm: 0.4690, dt: 162.12ms, tok/sec: 6316.24\n",
      "step   47, loss: 0.109292, norm: 0.4000, dt: 169.68ms, tok/sec: 6034.75\n",
      "step   48, loss: 0.108028, norm: 0.5033, dt: 162.58ms, tok/sec: 6298.37\n",
      "step   49, loss: 0.076308, norm: 0.3110, dt: 171.19ms, tok/sec: 5981.64\n",
      "step   50, loss: 0.071015, norm: 0.3265, dt: 171.33ms, tok/sec: 5976.82\n",
      "step   51, loss: 0.052914, norm: 0.2320, dt: 176.35ms, tok/sec: 5806.55\n",
      "step   52, loss: 0.048886, norm: 0.1989, dt: 169.92ms, tok/sec: 6026.34\n",
      "step   53, loss: 0.036914, norm: 0.1484, dt: 182.01ms, tok/sec: 5626.00\n",
      "step   54, loss: 0.037117, norm: 0.1653, dt: 152.19ms, tok/sec: 6728.30\n",
      "step   55, loss: 0.027198, norm: 0.1132, dt: 172.55ms, tok/sec: 5934.46\n",
      "step   56, loss: 0.025726, norm: 0.1121, dt: 175.07ms, tok/sec: 5849.25\n",
      "step   57, loss: 0.027554, norm: 0.1861, dt: 161.78ms, tok/sec: 6329.50\n",
      "step   58, loss: 0.018186, norm: 0.0691, dt: 154.84ms, tok/sec: 6613.19\n",
      "step   59, loss: 0.018976, norm: 0.1128, dt: 176.92ms, tok/sec: 5787.97\n",
      "step   60, loss: 0.017378, norm: 0.1270, dt: 183.60ms, tok/sec: 5577.26\n",
      "step   61, loss: 0.013931, norm: 0.0704, dt: 156.58ms, tok/sec: 6539.60\n",
      "step   62, loss: 0.011944, norm: 0.0834, dt: 178.47ms, tok/sec: 5737.56\n",
      "step   63, loss: 0.013264, norm: 0.0942, dt: 167.39ms, tok/sec: 6117.63\n",
      "step   64, loss: 0.009386, norm: 0.0645, dt: 182.81ms, tok/sec: 5601.31\n",
      "step   65, loss: 0.009638, norm: 0.0761, dt: 167.59ms, tok/sec: 6110.18\n",
      "step   66, loss: 0.011825, norm: 0.0970, dt: 163.21ms, tok/sec: 6273.98\n",
      "step   67, loss: 0.006577, norm: 0.0225, dt: 170.88ms, tok/sec: 5992.64\n",
      "step   68, loss: 0.010547, norm: 0.0974, dt: 185.70ms, tok/sec: 5514.31\n",
      "step   69, loss: 0.006592, norm: 0.0642, dt: 181.41ms, tok/sec: 5644.58\n",
      "step   70, loss: 0.006327, norm: 0.0469, dt: 162.45ms, tok/sec: 6303.50\n",
      "step   71, loss: 0.005865, norm: 0.0659, dt: 173.59ms, tok/sec: 5898.98\n",
      "step   72, loss: 0.008934, norm: 0.0742, dt: 164.96ms, tok/sec: 6207.46\n",
      "step   73, loss: 0.004597, norm: 0.0440, dt: 190.67ms, tok/sec: 5370.62\n",
      "step   74, loss: 0.008285, norm: 0.0801, dt: 170.86ms, tok/sec: 5993.30\n",
      "step   75, loss: 0.004393, norm: 0.0395, dt: 154.30ms, tok/sec: 6636.40\n",
      "step   76, loss: 0.004196, norm: 0.0335, dt: 142.64ms, tok/sec: 7179.12\n",
      "step   77, loss: 0.005997, norm: 0.0657, dt: 158.98ms, tok/sec: 6441.24\n",
      "step   78, loss: 0.003979, norm: 0.0488, dt: 157.98ms, tok/sec: 6481.79\n",
      "step   79, loss: 0.005918, norm: 0.0529, dt: 155.75ms, tok/sec: 6574.64\n",
      "step   80, loss: 0.003861, norm: 0.0522, dt: 151.33ms, tok/sec: 6766.48\n",
      "step   81, loss: 0.005253, norm: 0.0462, dt: 176.62ms, tok/sec: 5797.60\n",
      "step   82, loss: 0.002994, norm: 0.0356, dt: 173.05ms, tok/sec: 5917.42\n",
      "step   83, loss: 0.004593, norm: 0.0548, dt: 160.02ms, tok/sec: 6399.21\n",
      "step   84, loss: 0.003153, norm: 0.0328, dt: 150.20ms, tok/sec: 6817.74\n",
      "step   85, loss: 0.003511, norm: 0.0329, dt: 158.93ms, tok/sec: 6443.00\n",
      "step   86, loss: 0.003660, norm: 0.0457, dt: 150.78ms, tok/sec: 6791.17\n",
      "step   87, loss: 0.003911, norm: 0.0469, dt: 166.08ms, tok/sec: 6165.53\n",
      "step   88, loss: 0.003087, norm: 0.0323, dt: 166.68ms, tok/sec: 6143.34\n",
      "step   89, loss: 0.003026, norm: 0.0440, dt: 177.09ms, tok/sec: 5782.32\n",
      "step   90, loss: 0.003802, norm: 0.0284, dt: 198.10ms, tok/sec: 5169.23\n",
      "step   91, loss: 0.002383, norm: 0.0330, dt: 168.54ms, tok/sec: 6075.88\n",
      "step   92, loss: 0.003340, norm: 0.0428, dt: 164.81ms, tok/sec: 6213.06\n",
      "step   93, loss: 0.003218, norm: 0.0364, dt: 166.86ms, tok/sec: 6136.76\n",
      "step   94, loss: 0.001929, norm: 0.0154, dt: 166.77ms, tok/sec: 6140.34\n",
      "step   95, loss: 0.003916, norm: 0.0483, dt: 171.31ms, tok/sec: 5977.58\n",
      "step   96, loss: 0.002766, norm: 0.0352, dt: 187.10ms, tok/sec: 5472.92\n",
      "step   97, loss: 0.002681, norm: 0.0310, dt: 153.71ms, tok/sec: 6661.82\n",
      "step   98, loss: 0.002654, norm: 0.0395, dt: 171.32ms, tok/sec: 5977.05\n",
      "step   99, loss: 0.003487, norm: 0.0284, dt: 212.29ms, tok/sec: 4823.50\n",
      "step  100, loss: 0.002156, norm: 0.0320, dt: 166.15ms, tok/sec: 6162.97\n",
      "step  101, loss: 0.003479, norm: 0.0426, dt: 219.51ms, tok/sec: 4664.97\n",
      "step  102, loss: 0.002462, norm: 0.0292, dt: 164.28ms, tok/sec: 6233.11\n",
      "step  103, loss: 0.001641, norm: 0.0159, dt: 216.75ms, tok/sec: 4724.34\n",
      "step  104, loss: 0.004174, norm: 0.0486, dt: 166.78ms, tok/sec: 6139.95\n",
      "step  105, loss: 0.002005, norm: 0.0248, dt: 160.71ms, tok/sec: 6371.85\n",
      "step  106, loss: 0.002985, norm: 0.0355, dt: 155.93ms, tok/sec: 6567.22\n",
      "step  107, loss: 0.002452, norm: 0.0356, dt: 168.02ms, tok/sec: 6094.59\n",
      "step  108, loss: 0.002966, norm: 0.0201, dt: 165.25ms, tok/sec: 6196.77\n",
      "step  109, loss: 0.002166, norm: 0.0319, dt: 149.90ms, tok/sec: 6831.01\n",
      "step  110, loss: 0.003279, norm: 0.0383, dt: 166.94ms, tok/sec: 6134.10\n",
      "step  111, loss: 0.002060, norm: 0.0243, dt: 159.00ms, tok/sec: 6440.35\n",
      "step  112, loss: 0.001646, norm: 0.0189, dt: 170.80ms, tok/sec: 5995.33\n",
      "step  113, loss: 0.004072, norm: 0.0446, dt: 170.24ms, tok/sec: 6014.90\n",
      "step  114, loss: 0.001664, norm: 0.0184, dt: 149.77ms, tok/sec: 6837.03\n",
      "step  115, loss: 0.003070, norm: 0.0355, dt: 155.31ms, tok/sec: 6593.41\n",
      "step  116, loss: 0.002199, norm: 0.0306, dt: 167.00ms, tok/sec: 6131.78\n",
      "step  117, loss: 0.002632, norm: 0.0133, dt: 166.46ms, tok/sec: 6151.78\n",
      "step  118, loss: 0.002350, norm: 0.0315, dt: 150.36ms, tok/sec: 6810.38\n",
      "step  119, loss: 0.002726, norm: 0.0307, dt: 167.17ms, tok/sec: 6125.51\n",
      "step  120, loss: 0.002088, norm: 0.0247, dt: 154.46ms, tok/sec: 6629.39\n",
      "step  121, loss: 0.001536, norm: 0.0181, dt: 161.94ms, tok/sec: 6323.20\n",
      "step  122, loss: 0.004053, norm: 0.0405, dt: 158.17ms, tok/sec: 6474.02\n",
      "step  123, loss: 0.001452, norm: 0.0149, dt: 158.65ms, tok/sec: 6454.65\n",
      "step  124, loss: 0.003241, norm: 0.0354, dt: 168.98ms, tok/sec: 6059.92\n",
      "step  125, loss: 0.001712, norm: 0.0229, dt: 205.56ms, tok/sec: 4981.39\n",
      "step  126, loss: 0.002554, norm: 0.0134, dt: 150.64ms, tok/sec: 6797.89\n",
      "step  127, loss: 0.002436, norm: 0.0293, dt: 166.97ms, tok/sec: 6132.97\n",
      "step  128, loss: 0.002303, norm: 0.0254, dt: 163.49ms, tok/sec: 6263.27\n",
      "step  129, loss: 0.002454, norm: 0.0280, dt: 184.23ms, tok/sec: 5558.12\n",
      "step  130, loss: 0.001346, norm: 0.0159, dt: 166.35ms, tok/sec: 6155.66\n",
      "step  131, loss: 0.003643, norm: 0.0359, dt: 167.18ms, tok/sec: 6124.97\n",
      "step  132, loss: 0.001359, norm: 0.0140, dt: 166.49ms, tok/sec: 6150.62\n",
      "step  133, loss: 0.003285, norm: 0.0335, dt: 167.48ms, tok/sec: 6114.29\n",
      "step  134, loss: 0.001265, norm: 0.0154, dt: 149.63ms, tok/sec: 6843.57\n",
      "step  135, loss: 0.002716, norm: 0.0177, dt: 166.67ms, tok/sec: 6143.96\n",
      "step  136, loss: 0.002032, norm: 0.0245, dt: 156.70ms, tok/sec: 6534.89\n",
      "step  137, loss: 0.002219, norm: 0.0241, dt: 190.56ms, tok/sec: 5373.72\n",
      "step  138, loss: 0.002633, norm: 0.0281, dt: 164.47ms, tok/sec: 6226.21\n",
      "step  139, loss: 0.001192, norm: 0.0142, dt: 170.82ms, tok/sec: 5994.57\n",
      "step  140, loss: 0.002959, norm: 0.0303, dt: 164.88ms, tok/sec: 6210.48\n",
      "step  141, loss: 0.001442, norm: 0.0156, dt: 304.75ms, tok/sec: 3360.10\n",
      "step  142, loss: 0.002906, norm: 0.0298, dt: 145.90ms, tok/sec: 7018.69\n",
      "step  143, loss: 0.001138, norm: 0.0138, dt: 150.90ms, tok/sec: 6785.97\n",
      "step  144, loss: 0.002857, norm: 0.0199, dt: 169.91ms, tok/sec: 6026.79\n",
      "step  145, loss: 0.001494, norm: 0.0189, dt: 163.15ms, tok/sec: 6276.25\n",
      "step  146, loss: 0.002384, norm: 0.0250, dt: 168.67ms, tok/sec: 6071.14\n",
      "step  147, loss: 0.002251, norm: 0.0244, dt: 181.64ms, tok/sec: 5637.52\n",
      "step  148, loss: 0.001132, norm: 0.0138, dt: 173.19ms, tok/sec: 5912.53\n",
      "step  149, loss: 0.002660, norm: 0.0273, dt: 159.32ms, tok/sec: 6427.24\n",
      "step  150, loss: 0.001534, norm: 0.0173, dt: 167.24ms, tok/sec: 6123.04\n",
      "step  151, loss: 0.002595, norm: 0.0268, dt: 150.55ms, tok/sec: 6801.69\n",
      "step  152, loss: 0.001195, norm: 0.0154, dt: 166.76ms, tok/sec: 6140.40\n",
      "step  153, loss: 0.002684, norm: 0.0176, dt: 168.26ms, tok/sec: 6085.76\n",
      "step  154, loss: 0.001304, norm: 0.0170, dt: 164.39ms, tok/sec: 6229.19\n",
      "step  155, loss: 0.002457, norm: 0.0253, dt: 166.78ms, tok/sec: 6139.86\n",
      "step  156, loss: 0.001888, norm: 0.0210, dt: 167.10ms, tok/sec: 6128.09\n",
      "step  157, loss: 0.001143, norm: 0.0145, dt: 166.23ms, tok/sec: 6160.28\n",
      "step  158, loss: 0.002563, norm: 0.0264, dt: 174.67ms, tok/sec: 5862.50\n",
      "step  159, loss: 0.001478, norm: 0.0170, dt: 161.11ms, tok/sec: 6356.00\n",
      "step  160, loss: 0.002457, norm: 0.0254, dt: 174.05ms, tok/sec: 5883.52\n",
      "step  161, loss: 0.001242, norm: 0.0166, dt: 157.10ms, tok/sec: 6518.10\n",
      "step  162, loss: 0.002442, norm: 0.0145, dt: 157.70ms, tok/sec: 6493.53\n",
      "step  163, loss: 0.001328, norm: 0.0177, dt: 166.41ms, tok/sec: 6153.50\n",
      "step  164, loss: 0.002288, norm: 0.0239, dt: 151.36ms, tok/sec: 6765.40\n",
      "step  165, loss: 0.001761, norm: 0.0199, dt: 215.46ms, tok/sec: 4752.56\n",
      "step  166, loss: 0.001128, norm: 0.0147, dt: 158.00ms, tok/sec: 6480.96\n",
      "step  167, loss: 0.002550, norm: 0.0262, dt: 168.48ms, tok/sec: 6077.79\n",
      "step  168, loss: 0.001371, norm: 0.0159, dt: 187.67ms, tok/sec: 5456.31\n",
      "step  169, loss: 0.002388, norm: 0.0249, dt: 169.46ms, tok/sec: 6042.59\n",
      "step  170, loss: 0.001191, norm: 0.0164, dt: 172.17ms, tok/sec: 5947.53\n",
      "step  171, loss: 0.002299, norm: 0.0129, dt: 178.24ms, tok/sec: 5745.17\n",
      "step  172, loss: 0.001390, norm: 0.0185, dt: 182.03ms, tok/sec: 5625.37\n",
      "step  173, loss: 0.002053, norm: 0.0220, dt: 167.41ms, tok/sec: 6116.77\n",
      "step  174, loss: 0.001794, norm: 0.0203, dt: 174.19ms, tok/sec: 5878.60\n",
      "step  175, loss: 0.001051, norm: 0.0142, dt: 159.26ms, tok/sec: 6429.65\n",
      "step  176, loss: 0.002521, norm: 0.0257, dt: 167.25ms, tok/sec: 6122.60\n",
      "step  177, loss: 0.001284, norm: 0.0151, dt: 161.48ms, tok/sec: 6341.33\n",
      "step  178, loss: 0.002361, norm: 0.0246, dt: 154.60ms, tok/sec: 6623.69\n",
      "step  179, loss: 0.001065, norm: 0.0150, dt: 162.73ms, tok/sec: 6292.72\n",
      "step  180, loss: 0.002262, norm: 0.0129, dt: 157.15ms, tok/sec: 6515.93\n",
      "step  181, loss: 0.001365, norm: 0.0182, dt: 145.77ms, tok/sec: 7024.58\n",
      "step  182, loss: 0.001914, norm: 0.0209, dt: 167.01ms, tok/sec: 6131.27\n",
      "step  183, loss: 0.001852, norm: 0.0208, dt: 166.64ms, tok/sec: 6145.15\n",
      "step  184, loss: 0.000975, norm: 0.0136, dt: 166.52ms, tok/sec: 6149.56\n",
      "step  185, loss: 0.002371, norm: 0.0246, dt: 165.98ms, tok/sec: 6169.59\n",
      "step  186, loss: 0.001257, norm: 0.0151, dt: 161.78ms, tok/sec: 6329.47\n",
      "step  187, loss: 0.002310, norm: 0.0241, dt: 156.78ms, tok/sec: 6531.25\n",
      "step  188, loss: 0.000946, norm: 0.0138, dt: 163.36ms, tok/sec: 6268.39\n",
      "step  189, loss: 0.002287, norm: 0.0136, dt: 186.59ms, tok/sec: 5487.86\n",
      "step  190, loss: 0.001221, norm: 0.0169, dt: 183.40ms, tok/sec: 5583.36\n",
      "step  191, loss: 0.001893, norm: 0.0208, dt: 191.43ms, tok/sec: 5349.16\n",
      "step  192, loss: 0.001814, norm: 0.0204, dt: 163.11ms, tok/sec: 6277.88\n",
      "step  193, loss: 0.000939, norm: 0.0135, dt: 151.14ms, tok/sec: 6775.07\n",
      "step  194, loss: 0.002159, norm: 0.0230, dt: 149.02ms, tok/sec: 6871.49\n",
      "step  195, loss: 0.001301, norm: 0.0158, dt: 144.24ms, tok/sec: 7099.17\n",
      "step  196, loss: 0.002187, norm: 0.0232, dt: 154.11ms, tok/sec: 6644.72\n",
      "step  197, loss: 0.000902, norm: 0.0134, dt: 182.93ms, tok/sec: 5597.91\n",
      "step  198, loss: 0.002289, norm: 0.0138, dt: 150.06ms, tok/sec: 6823.98\n",
      "step  199, loss: 0.001072, norm: 0.0155, dt: 175.10ms, tok/sec: 5848.17\n",
      "step  200, loss: 0.001908, norm: 0.0210, dt: 177.95ms, tok/sec: 5754.46\n",
      "step  201, loss: 0.001695, norm: 0.0195, dt: 158.75ms, tok/sec: 6450.32\n",
      "step  202, loss: 0.000923, norm: 0.0136, dt: 175.99ms, tok/sec: 5818.52\n",
      "step  203, loss: 0.002026, norm: 0.0221, dt: 157.17ms, tok/sec: 6515.16\n",
      "step  204, loss: 0.001340, norm: 0.0163, dt: 167.42ms, tok/sec: 6116.22\n",
      "step  205, loss: 0.002055, norm: 0.0222, dt: 166.30ms, tok/sec: 6157.61\n",
      "step  206, loss: 0.000907, norm: 0.0137, dt: 160.88ms, tok/sec: 6365.08\n",
      "step  207, loss: 0.002236, norm: 0.0134, dt: 160.00ms, tok/sec: 6400.12\n",
      "step  208, loss: 0.001011, norm: 0.0150, dt: 157.56ms, tok/sec: 6499.06\n",
      "step  209, loss: 0.001873, norm: 0.0208, dt: 168.95ms, tok/sec: 6061.13\n",
      "step  210, loss: 0.001615, norm: 0.0189, dt: 164.53ms, tok/sec: 6223.66\n",
      "step  211, loss: 0.000896, norm: 0.0136, dt: 176.62ms, tok/sec: 5797.90\n",
      "step  212, loss: 0.001984, norm: 0.0218, dt: 140.18ms, tok/sec: 7304.66\n",
      "step  213, loss: 0.001324, norm: 0.0163, dt: 182.40ms, tok/sec: 5613.94\n",
      "step  214, loss: 0.001982, norm: 0.0218, dt: 164.62ms, tok/sec: 6220.30\n",
      "step  215, loss: 0.000892, norm: 0.0138, dt: 156.70ms, tok/sec: 6534.96\n",
      "step  216, loss: 0.002185, norm: 0.0130, dt: 159.48ms, tok/sec: 6420.73\n",
      "step  217, loss: 0.000999, norm: 0.0150, dt: 183.58ms, tok/sec: 5577.87\n",
      "step  218, loss: 0.001803, norm: 0.0204, dt: 149.82ms, tok/sec: 6834.85\n",
      "step  219, loss: 0.001601, norm: 0.0189, dt: 166.83ms, tok/sec: 6138.01\n",
      "step  220, loss: 0.000865, norm: 0.0134, dt: 181.05ms, tok/sec: 5655.90\n",
      "step  221, loss: 0.001945, norm: 0.0216, dt: 164.70ms, tok/sec: 6217.26\n",
      "step  222, loss: 0.001300, norm: 0.0162, dt: 156.58ms, tok/sec: 6539.95\n",
      "step  223, loss: 0.001947, norm: 0.0216, dt: 156.50ms, tok/sec: 6543.10\n",
      "step  224, loss: 0.000851, norm: 0.0134, dt: 135.83ms, tok/sec: 7538.64\n",
      "step  225, loss: 0.002169, norm: 0.0130, dt: 166.90ms, tok/sec: 6135.28\n",
      "step  226, loss: 0.000969, norm: 0.0148, dt: 173.40ms, tok/sec: 5905.38\n",
      "step  227, loss: 0.001755, norm: 0.0201, dt: 162.89ms, tok/sec: 6286.63\n",
      "step  228, loss: 0.001592, norm: 0.0188, dt: 150.40ms, tok/sec: 6808.72\n",
      "step  229, loss: 0.000844, norm: 0.0133, dt: 155.73ms, tok/sec: 6575.58\n",
      "step  230, loss: 0.001872, norm: 0.0211, dt: 166.89ms, tok/sec: 6135.76\n",
      "step  231, loss: 0.001306, norm: 0.0163, dt: 166.53ms, tok/sec: 6149.06\n",
      "step  232, loss: 0.001898, norm: 0.0212, dt: 167.06ms, tok/sec: 6129.37\n",
      "step  233, loss: 0.000822, norm: 0.0132, dt: 191.83ms, tok/sec: 5338.13\n",
      "step  234, loss: 0.002163, norm: 0.0130, dt: 141.24ms, tok/sec: 7250.31\n",
      "step  235, loss: 0.000920, norm: 0.0144, dt: 193.15ms, tok/sec: 5301.62\n",
      "step  236, loss: 0.001733, norm: 0.0199, dt: 162.23ms, tok/sec: 6311.90\n",
      "step  237, loss: 0.001560, norm: 0.0186, dt: 170.73ms, tok/sec: 5997.69\n",
      "step  238, loss: 0.000829, norm: 0.0133, dt: 160.16ms, tok/sec: 6393.80\n",
      "step  239, loss: 0.001809, norm: 0.0206, dt: 155.79ms, tok/sec: 6572.75\n",
      "step  240, loss: 0.001320, norm: 0.0166, dt: 167.16ms, tok/sec: 6125.81\n",
      "step  241, loss: 0.001837, norm: 0.0208, dt: 165.55ms, tok/sec: 6185.44\n",
      "step  242, loss: 0.000813, norm: 0.0132, dt: 150.30ms, tok/sec: 6812.83\n",
      "step  243, loss: 0.002145, norm: 0.0129, dt: 268.04ms, tok/sec: 3820.36\n",
      "step  244, loss: 0.000890, norm: 0.0141, dt: 161.80ms, tok/sec: 6328.80\n",
      "step  245, loss: 0.001706, norm: 0.0198, dt: 157.12ms, tok/sec: 6517.33\n",
      "step  246, loss: 0.001534, norm: 0.0184, dt: 175.30ms, tok/sec: 5841.33\n",
      "step  247, loss: 0.000812, norm: 0.0132, dt: 174.86ms, tok/sec: 5856.15\n",
      "step  248, loss: 0.001773, norm: 0.0204, dt: 150.44ms, tok/sec: 6806.90\n",
      "step  249, loss: 0.001321, norm: 0.0166, dt: 166.31ms, tok/sec: 6157.16\n",
      "step  250, loss: 0.001797, norm: 0.0206, dt: 164.24ms, tok/sec: 6234.83\n",
      "step  251, loss: 0.000799, norm: 0.0131, dt: 166.28ms, tok/sec: 6158.19\n",
      "step  252, loss: 0.002130, norm: 0.0128, dt: 150.69ms, tok/sec: 6795.19\n",
      "step  253, loss: 0.000871, norm: 0.0140, dt: 152.39ms, tok/sec: 6719.57\n",
      "step  254, loss: 0.001674, norm: 0.0196, dt: 165.94ms, tok/sec: 6171.08\n",
      "step  255, loss: 0.001526, norm: 0.0184, dt: 158.32ms, tok/sec: 6467.73\n",
      "step  256, loss: 0.000801, norm: 0.0132, dt: 196.90ms, tok/sec: 5200.62\n",
      "step  257, loss: 0.001740, norm: 0.0202, dt: 171.14ms, tok/sec: 5983.24\n",
      "step  258, loss: 0.001355, norm: 0.0173, dt: 168.03ms, tok/sec: 6094.10\n",
      "step  259, loss: 0.283451, norm: 13.5162, dt: 173.83ms, tok/sec: 5890.68\n",
      "step  260, loss: 0.108792, norm: 2.6044, dt: 142.30ms, tok/sec: 7196.08\n",
      "step  261, loss: 0.343688, norm: 7.6663, dt: 181.62ms, tok/sec: 5638.30\n",
      "step  262, loss: 0.273614, norm: 3.0249, dt: 164.46ms, tok/sec: 6226.56\n",
      "step  263, loss: 0.355816, norm: 2.6189, dt: 170.52ms, tok/sec: 6005.18\n",
      "step  264, loss: 0.318202, norm: 3.3864, dt: 183.14ms, tok/sec: 5591.26\n",
      "step  265, loss: 0.188643, norm: 1.7206, dt: 167.01ms, tok/sec: 6131.38\n",
      "step  266, loss: 0.245369, norm: 2.3201, dt: 170.99ms, tok/sec: 5988.77\n",
      "step  267, loss: 0.161142, norm: 1.6205, dt: 170.42ms, tok/sec: 6008.74\n",
      "step  268, loss: 0.135825, norm: 1.4157, dt: 173.46ms, tok/sec: 5903.26\n",
      "step  269, loss: 0.152445, norm: 1.6082, dt: 159.22ms, tok/sec: 6431.24\n",
      "step  270, loss: 0.119192, norm: 1.2535, dt: 172.25ms, tok/sec: 5944.95\n",
      "step  271, loss: 0.071055, norm: 0.8419, dt: 168.31ms, tok/sec: 6084.05\n",
      "step  272, loss: 0.069568, norm: 0.8516, dt: 151.41ms, tok/sec: 6763.18\n",
      "step  273, loss: 0.055002, norm: 0.7011, dt: 165.89ms, tok/sec: 6172.82\n",
      "step  274, loss: 0.044345, norm: 0.6273, dt: 165.23ms, tok/sec: 6197.32\n",
      "step  275, loss: 0.046755, norm: 0.6399, dt: 167.83ms, tok/sec: 6101.33\n",
      "step  276, loss: 0.064145, norm: 0.8797, dt: 164.62ms, tok/sec: 6220.24\n",
      "step  277, loss: 0.039502, norm: 0.5286, dt: 169.40ms, tok/sec: 6044.70\n",
      "step  278, loss: 0.051934, norm: 0.8718, dt: 165.49ms, tok/sec: 6187.85\n",
      "step  279, loss: 0.031069, norm: 0.4001, dt: 191.65ms, tok/sec: 5342.94\n",
      "step  280, loss: 0.035819, norm: 0.5450, dt: 174.83ms, tok/sec: 5857.05\n",
      "step  281, loss: 0.022563, norm: 0.2783, dt: 186.03ms, tok/sec: 5504.46\n",
      "step  282, loss: 0.027490, norm: 0.3906, dt: 159.70ms, tok/sec: 6412.10\n",
      "step  283, loss: 0.022509, norm: 0.3471, dt: 149.91ms, tok/sec: 6830.86\n",
      "step  284, loss: 0.015116, norm: 0.1685, dt: 170.62ms, tok/sec: 6001.59\n",
      "step  285, loss: 0.017882, norm: 0.2840, dt: 185.04ms, tok/sec: 5533.94\n",
      "step  286, loss: 0.016802, norm: 0.2849, dt: 162.88ms, tok/sec: 6286.75\n",
      "step  287, loss: 0.015388, norm: 0.3441, dt: 185.24ms, tok/sec: 5527.93\n",
      "step  288, loss: 0.012234, norm: 0.1395, dt: 167.19ms, tok/sec: 6124.86\n",
      "step  289, loss: 0.017213, norm: 0.2469, dt: 182.61ms, tok/sec: 5607.58\n",
      "step  290, loss: 0.014111, norm: 0.2578, dt: 170.82ms, tok/sec: 5994.57\n",
      "step  291, loss: 0.009787, norm: 0.0921, dt: 176.06ms, tok/sec: 5816.06\n",
      "step  292, loss: 0.006950, norm: 0.0660, dt: 166.42ms, tok/sec: 6153.11\n",
      "step  293, loss: 0.011890, norm: 0.1892, dt: 203.63ms, tok/sec: 5028.64\n",
      "step  294, loss: 0.012942, norm: 0.2308, dt: 158.19ms, tok/sec: 6473.03\n",
      "step  295, loss: 0.006522, norm: 0.0730, dt: 153.08ms, tok/sec: 6689.32\n",
      "step  296, loss: 0.005275, norm: 0.0509, dt: 175.23ms, tok/sec: 5843.71\n",
      "step  297, loss: 0.006048, norm: 0.0486, dt: 180.99ms, tok/sec: 5657.74\n",
      "step  298, loss: 0.005394, norm: 0.0718, dt: 181.58ms, tok/sec: 5639.40\n",
      "step  299, loss: 0.005587, norm: 0.0595, dt: 182.16ms, tok/sec: 5621.53\n",
      "step  300, loss: 0.004525, norm: 0.0508, dt: 169.61ms, tok/sec: 6037.23\n",
      "step  301, loss: 0.003410, norm: 0.0381, dt: 142.90ms, tok/sec: 7165.70\n",
      "step  302, loss: 0.005083, norm: 0.0554, dt: 172.28ms, tok/sec: 5943.93\n",
      "step  303, loss: 0.002676, norm: 0.0233, dt: 184.83ms, tok/sec: 5540.28\n",
      "step  304, loss: 0.004813, norm: 0.0537, dt: 169.22ms, tok/sec: 6051.24\n",
      "step  305, loss: 0.002310, norm: 0.0256, dt: 164.59ms, tok/sec: 6221.51\n",
      "step  306, loss: 0.003631, norm: 0.0270, dt: 166.75ms, tok/sec: 6140.78\n",
      "step  307, loss: 0.002669, norm: 0.0348, dt: 183.17ms, tok/sec: 5590.57\n",
      "step  308, loss: 0.002737, norm: 0.0321, dt: 153.59ms, tok/sec: 6667.23\n",
      "step  309, loss: 0.003013, norm: 0.0381, dt: 188.82ms, tok/sec: 5423.10\n",
      "step  310, loss: 0.002095, norm: 0.0271, dt: 174.73ms, tok/sec: 5860.54\n",
      "step  311, loss: 0.002384, norm: 0.0308, dt: 195.03ms, tok/sec: 5250.56\n",
      "step  312, loss: 0.002339, norm: 0.0310, dt: 206.18ms, tok/sec: 4966.46\n",
      "step  313, loss: 0.002643, norm: 0.0355, dt: 194.47ms, tok/sec: 5265.72\n",
      "step  314, loss: 0.001352, norm: 0.0203, dt: 191.14ms, tok/sec: 5357.43\n",
      "step  315, loss: 0.003011, norm: 0.0266, dt: 167.89ms, tok/sec: 6099.09\n",
      "step  316, loss: 0.001405, norm: 0.0228, dt: 172.72ms, tok/sec: 5928.69\n",
      "step  317, loss: 0.002091, norm: 0.0295, dt: 179.94ms, tok/sec: 5690.67\n",
      "step  318, loss: 0.002338, norm: 0.0332, dt: 258.76ms, tok/sec: 3957.37\n",
      "step  319, loss: 0.001181, norm: 0.0174, dt: 182.53ms, tok/sec: 5610.17\n",
      "step  320, loss: 0.002221, norm: 0.0317, dt: 167.70ms, tok/sec: 6106.27\n",
      "step  321, loss: 0.001947, norm: 0.0292, dt: 196.83ms, tok/sec: 5202.36\n",
      "step  322, loss: 0.002006, norm: 0.0296, dt: 176.66ms, tok/sec: 5796.45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[358], line 172\u001b[0m\n\u001b[0;32m    170\u001b[0m         logits, loss \u001b[38;5;241m=\u001b[39m model(x, y)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m grad_accum_steps\n\u001b[0;32m    174\u001b[0m loss_accum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[356], line 186\u001b[0m, in \u001b[0;36mGPT.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m    184\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mdrop(tok_emb \u001b[38;5;241m+\u001b[39m pos_emb)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh:\n\u001b[1;32m--> 186\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mln_f(x)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;66;03m# if we are given some desired targets also calculate the loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[356], line 108\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 108\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x))\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[356], line 69\u001b[0m, in \u001b[0;36mCausalSelfAttention.forward\u001b[1;34m(self, x, return_attention)\u001b[0m\n\u001b[0;32m     66\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mscaled_dot_product_attention(q, k, v, attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m, is_causal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# manual implementation of attention\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     att \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     70\u001b[0m     att \u001b[38;5;241m=\u001b[39m att\u001b[38;5;241m.\u001b[39mmasked_fill(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[:,:,:T,:T] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     71\u001b[0m     att \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(att, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def load_tokens(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "      file_content = f.read()\n",
    "\n",
    "    npt = np.frombuffer(file_content, dtype=np.uint16)\n",
    "    npt = npt.astype(np.int32)\n",
    "    ptt = torch.tensor(npt, dtype=torch.long)\n",
    "\n",
    "    return ptt\n",
    "\n",
    "\n",
    "def get_most_likely_row(tokens, mask, logits):\n",
    "    shift_logits = (logits[..., :-1, :]).contiguous()\n",
    "    shift_tokens = (tokens[..., 1:]).contiguous()\n",
    "    flat_shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "    flat_shift_tokens = shift_tokens.view(-1)\n",
    "    shift_losses = F.cross_entropy(flat_shift_logits, flat_shift_tokens, reduction='none')\n",
    "    shift_losses = shift_losses.view(tokens.size(0), -1)\n",
    "    # now get the average loss just for the completion region (where mask == 1), in each row\n",
    "    shift_mask = (mask[..., 1:]).contiguous().to(logits.device) # we must shift mask, so we start at the last prompt token\n",
    "    masked_shift_losses = shift_losses * shift_mask\n",
    "    # sum and divide by the number of 1s in the mask\n",
    "    sum_loss = masked_shift_losses.sum(dim=1)\n",
    "    avg_loss = sum_loss / shift_mask.sum(dim=1)\n",
    "    # now we have a loss for each of the 4 completions\n",
    "    # the one with the lowest loss should be the most likely\n",
    "    pred_norm = avg_loss.argmin().item()\n",
    "    return pred_norm\n",
    "\n",
    "\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T,split):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        assert split in {'train', 'val'}\n",
    "\n",
    "        # get the shard filenames\n",
    "        data_root = \"./data/patufet-mini\"\n",
    "        shards = os.listdir(data_root)\n",
    "        shards = [s for s in shards if split in s]\n",
    "        shards = sorted(shards)\n",
    "        shards = [os.path.join(data_root, s) for s in shards]\n",
    "        print(\"Shards:\", shards)\n",
    "        self.shards = shards\n",
    "        assert len(shards) > 0, f\"no shards found for split {split}\"\n",
    "        print(f\"found {len(shards)} shards for split {split}\")\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # state, init at shard zero\n",
    "        self.current_shard = 0\n",
    "        self.tokens = load_tokens(self.shards[self.current_shard])\n",
    "        self.current_position = 0\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        buf = self.tokens[self.current_position : self.current_position+B*T+1]\n",
    "        x = (buf[:-1]).view(B, T) # inputs\n",
    "        y = (buf[1:]).view(B, T) # targets\n",
    "        # advance the position in the tensor\n",
    "        self.current_position += B * T\n",
    "        # if loading the next batch would be out of bounds, advance to next shard\n",
    "        if self.current_position + (B * T + 1) > len(self.tokens):\n",
    "            self.current_shard = (self.current_shard + 1) % len(self.shards)\n",
    "            self.tokens = load_tokens(self.shards[self.current_shard])\n",
    "            self.current_position = 0\n",
    "        return x, y\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# torchrun --standalone --nproc_per_node=8 train_gpt2.py\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "device_type = \"cuda\" if device.startswith(\"cuda\") else \"cpu\"\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "enc = Tokenizer.from_file(\"./tokenizer/mini.tokenizer.json\")\n",
    "\n",
    "\n",
    "total_batch_size = 1024\n",
    "B = 2\n",
    "T = 128\n",
    "\n",
    "\n",
    "grad_accum_steps = total_batch_size // (B*T)\n",
    "print(f\"Total desired batach size: {total_batch_size}\")\n",
    "print(f\"Calculated gradient accumulation steps: {grad_accum_steps}\")\n",
    "\n",
    "train_loader = DataLoaderLite(B=B, T =T, split=\"train\")\n",
    "val_loader = DataLoaderLite(B=B, T =T, split=\"val\")\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "model_config = AlojaConfig()\n",
    "\n",
    "model = Aloja(model_config)\n",
    "\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "use_compile = True\n",
    "model = torch.compile(model)\n",
    "\n",
    "max_lr = 3e-4\n",
    "min_lr = max_lr * 0.1\n",
    "warmup_steps = 200\n",
    "max_steps = 19000\n",
    "\n",
    "def get_lr(it):\n",
    "    if it < warmup_steps:\n",
    "        return max_lr * (it+1) / warmup_steps\n",
    "    if it > max_steps:\n",
    "        return min_lr\n",
    "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
    "    return min_lr + coeff * (max_lr - min_lr)\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas = (0.9, 0.95), eps=1e-8)\n",
    "\n",
    "model.train()\n",
    "optimizer = model.configure_optimizers(weight_decay=0.0, learning_rate=3e-4, device_type=device_type)\n",
    "\n",
    "log_dir = \"log\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_file = os.path.join(log_dir, f\"log.txt\")\n",
    "with open(log_file, \"w\") as f:\n",
    "    pass\n",
    "\n",
    "for step in range(max_steps):\n",
    "    t0 = time.time()\n",
    "    last_step = (step == max_steps -1)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss_accum = 0.0\n",
    "    for micro_step in range(grad_accum_steps):\n",
    "        x, y = train_loader.next_batch()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "                logits, loss = model(x, y)\n",
    "        else:\n",
    "            logits, loss = model(x, y)\n",
    "        loss = loss / grad_accum_steps\n",
    "        loss_accum += loss.detach()\n",
    "        loss.backward()\n",
    "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    lr = get_lr(step)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    optimizer.step()\n",
    "    if device_type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    dt = (t1 - t0)*1000\n",
    "    tokens_per_sec = (train_loader.B * train_loader.T * grad_accum_steps) / (t1-t0)\n",
    "    print(f\"step {step:4d}, loss: {loss_accum.item():.6f}, norm: {norm:.4f}, dt: {dt:.2f}ms, tok/sec: {tokens_per_sec:.2f}\")\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{step} train {loss_accum.item():.6f}\\n\")\n",
    "    if step > 0 and (step % 1000 == 0 or last_step):\n",
    "        checkpoint_path = os.path.join(log_dir, f\"model_{step:05d}.pt\")\n",
    "        checkpoint = {\n",
    "            'model': model.state_dict(),\n",
    "            'config': model.config,\n",
    "            'step': step,\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "9a20c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shards: ['./data/patufet-mini\\\\patufet_train_000001', './data/patufet-mini\\\\patufet_train_000002', './data/patufet-mini\\\\patufet_train_000003']\n",
      "found 3 shards for split train\n"
     ]
    }
   ],
   "source": [
    "train_loader2 = DataLoaderLite(B=B, T =T, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "639bed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([287, 288, 297, 405,  74, 288, 280, 399, 294, 376, 323, 300, 440, 443,\n",
      "        394, 273, 306, 328, 481,  92, 314,  88, 299, 280, 401, 268,  76, 276,\n",
      "         74, 294, 354, 307,  92, 275, 284,  82, 318, 291, 294, 273,  94,  75,\n",
      "        365, 277, 268, 326,  80, 289,  92,  18,  21, 291, 339,  82, 281, 348,\n",
      "        374, 460, 470, 288, 318,  75, 320, 270, 287, 275, 343,  74, 339,  82,\n",
      "        286, 362,  94, 313, 268, 270, 492, 273, 413, 456, 321, 291, 336,  94,\n",
      "        273, 297, 313,  86, 282,  82,  23, 392,  82, 429,  92, 301, 288, 330,\n",
      "         83, 280,  92, 401,  92, 432, 284, 315,  93, 416,  80, 271,  92,  18,\n",
      "        283, 330,  94, 268, 287, 299, 285,  93, 289,  74, 317, 339,  82, 326,\n",
      "        300, 306])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "a = (train_loader2.next_batch())\n",
    "print(a[0][0])\n",
    "print(train_loader2.current_shard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ea434ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ón res més que un maquillatge per poder seguir amagant el que realment la societat necessita saber en un estat democràtic del S.XXI.CYBERSQUIRRELS! - Infoself Group\\nCYBERSQUIRRELS!\\nCom alguns ja sabreu fa pocs dies (27 de novem'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(a[0][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "946386a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " us enlLa l'el dels? hojor con pa, no hoqu dat nos vort ens joquen el casta delhYBERS! Di l\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to generate text continuation\n",
    "def generate_text(model, tokenizer, input_text, max_length=50, temperature=0.1, top_k=1):\n",
    "    model.eval()\n",
    "    input_ids = torch.Tensor(np.array(tokenizer.encode(input_text).ids, dtype=np.int32)).type(torch.int32).to(device)\n",
    "\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    generated = input_ids\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(generated)\n",
    "        \n",
    "        # Select the logits of the last token\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "\n",
    "        # Apply top-k sampling\n",
    "        if top_k > 0:\n",
    "            top_k_values, top_k_indices = torch.topk(logits, top_k)\n",
    "            logits = torch.zeros_like(logits).scatter_(1, top_k_indices, top_k_values)\n",
    "        \n",
    "        # Convert logits to probabilities and sample\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        next_token = torch.multinomial(probabilities, num_samples=1)\n",
    "\n",
    "        # Append sampled token to generated sequence\n",
    "        generated = torch.cat((generated, next_token), dim=1)\n",
    "\n",
    "\n",
    "    # Decode the generated tokens to text\n",
    "    generated_text = tokenizer.decode(generated[0].tolist())\n",
    "    return generated_text\n",
    "\n",
    "# Example usage\n",
    "input_text = \"</s> \"\n",
    "generated_text = generate_text(model, tokenizer, input_text, max_length=50, temperature=1.0, top_k=50)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "374483b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " us enl \"cidors que sdeo que no és meu,nnil d man exaconiuim un pressarcç o pubar a una d'eia ens\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.Tensor(np.array(tokenizer.encode(input_text).ids, dtype=np.int32)).type(torch.int32).to(device)\n",
    "input_ids = input_ids.unsqueeze(0)\n",
    "generated = model.generate(input_ids, 50)\n",
    "generated_text = tokenizer.decode(generated[0].tolist())\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f450e9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' de presentar el tall tot sencer, hi he afegit ingredients, tal com he vist que es feia en alguna recepta'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([270, 490, 268, 387, 291, 230, 375,  85, 433, 283, 268,  76, 271,  21,\n",
    "         314,  82, 314,  78, 269,  79, 440, 330, 347,  80, 284, 381, 470,  21,\n",
    "         230, 375, 335, 314,  78, 300, 484, 294, 315, 299,  78, 333, 307, 326,\n",
    "          80, 289,  74, 474,  78,  89, 274])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "e44b8f82-8f1e-446f-9cb2-2df4270a1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def visualize_attention(model, tokenizer, sentence, layer_num, head_num):\n",
    "    # Tokenize the input sentence\n",
    "    input_ids = torch.Tensor(np.array(tokenizer.encode(sentence).ids, dtype=np.int32)).type(torch.int32)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Move input to the same device as the model\n",
    "    input_ids = input_ids.to(next(model.parameters()).device)\n",
    "    T = len(input_ids)\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "\n",
    "    \n",
    "    print(T)\n",
    "    x = model.embed_tokens(input_ids)\n",
    "\n",
    "\n",
    "    position_ids = torch.arange(T, device = x.device).unsqueeze(0)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    cos_sin = model.rotary_emb(x, position_ids)\n",
    "    \n",
    "    _, attention_weights = model.layers[layer_num].self_attn(x, cos_sin, return_attention=True)\n",
    "\n",
    "    # Select the attention weights for the specified head\n",
    "    attention_weights = attention_weights[0, head_num].detach().cpu().numpy()\n",
    "\n",
    "    # Plot the attention weights\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(attention_weights, cmap=\"viridis\", xticklabels=[str(enc.decode([ll])) for ll in input_ids.tolist()[0]], yticklabels=[str(enc.decode([ll])) for ll in input_ids.tolist()[0]])\n",
    "    plt.title(f\"Attention Weights - Layer {layer_num + 1}, Head {head_num + 1}\")\n",
    "    plt.xlabel(\"Key Position\")\n",
    "    plt.ylabel(\"Query Position\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0a7a34b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La nena juga amb les seves joguines'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.Tensor(np.array(tokenizer.encode(\"La nena juga amb les seves joguines\").ids, dtype=np.int32)).type(torch.int32)\n",
    "\n",
    "    \n",
    "    \n",
    "# Move input to the same device as the model\n",
    "input_ids = input_ids.to(next(model.parameters()).device)\n",
    "T = len(input_ids)\n",
    "input_ids = input_ids.unsqueeze(0)\n",
    "enc.decode(input_ids.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b6c89fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def visualize_attention(model, tokenizer, sentence, layer_num, head_num):\n",
    "    # Tokenize the input sentence\n",
    "    input_ids = torch.Tensor(np.array(tokenizer.encode(sentence).ids, dtype=np.int32)).type(torch.int32)\n",
    "\n",
    "    print(input_ids.tolist())\n",
    "\n",
    "    pos = torch.arange(0, len(input_ids), dtype=torch.long)\n",
    "    tok_emb = model.transformer.wte(input_ids) # token embeddings of shape (b, t, n_embd)\n",
    "    pos_emb = model.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
    "    x = model.transformer.drop(tok_emb + pos_emb)\n",
    "\n",
    "    x = x.unsqueeze(0)\n",
    "    \n",
    "    layer = model.transformer.h[layer_num]\n",
    "    _, attention_weights = layer.attn(x, return_attention=True)\n",
    "\n",
    "    # Select the attention weights for the specified head\n",
    "    attention_weights = attention_weights[0, head_num].detach().cpu().numpy()\n",
    "\n",
    "    # Plot the attention weights\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(attention_weights, cmap=\"viridis\", xticklabels=[str(enc.decode([ll])) for ll in input_ids.tolist()], yticklabels=[str(enc.decode([ll])) for ll in input_ids.tolist()])\n",
    "    plt.title(f\"Attention Weights - Layer {layer_num + 1}, Head {head_num + 1}\")\n",
    "    plt.xlabel(\"Key Position\")\n",
    "    plt.ylabel(\"Query Position\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "13ac7dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 230]]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "45761433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53, 74, 311, 268, 74, 397, 94, 80, 74, 344, 331, 336, 486, 397, 88, 334, 304, 267]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"./tokenizer/mini.tokenizer.json\")\n",
    "\n",
    "\n",
    "sentence = \"La nena juga amb les seves joguines\"\n",
    "layer_num = 0  # Specify the layer number (0-indexed)\n",
    "head_num = 0  # Specify the head number (0-indexed)\n",
    "\n",
    "visualize_attention(model, tokenizer, sentence, layer_num, head_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3697bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_29452\\3942902272.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"./src/model_00576.pt\", map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./src/model_00576.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9864264",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint['config'].intermediate_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "39c74720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlojaConfig:\n",
    "    block_size: int = 2048\n",
    "    vocab_size: int = 65536\n",
    "    n_layer: int = 30\n",
    "    n_head: int = 8\n",
    "    n_embd: int = 768\n",
    "    intermediate_size = 2048 # 3072\n",
    "    n_kv_heads: int = 4 # nombre de grups de query\n",
    "    norm_eps: int = 1e-05\n",
    "    rope_theta: float = 1000.0\n",
    "    use_scaled_rope: bool = False\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len:int = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6e5f5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AlojaConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6359c62e-fccb-4d48-a777-e4eccc0fc2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bad = Aloja(config)\n",
    "model_bad.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3df9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def visualize_attention(model, tokenizer, sentence, layer_num, head_num):\n",
    "    # Tokenize the input sentence\n",
    "    input_ids = torch.Tensor(np.array(tokenizer.encode(sentence).ids, dtype=np.int32)).type(torch.int32)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Move input to the same device as the model\n",
    "    input_ids = input_ids.to(next(model.parameters()).device)\n",
    "    T = len(input_ids)\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "\n",
    "    \n",
    "    print(T)\n",
    "    mask = torch.full((T, T), float(\"-inf\"), device=input_ids.device)\n",
    "    mask = torch.triu(mask, diagonal=1)\n",
    "    mask = mask.type_as(x)\n",
    "\n",
    "    # Forward pass through the model with return_attention=True\n",
    "    print(input_ids[0])\n",
    "    passed = model.transformer.wte(input_ids)\n",
    "    print(passed.shape)\n",
    "\n",
    "    freqs = model.freqs[:T]\n",
    "    \n",
    "    _, attention_weights = model.transformer.h[layer_num].attn(passed, freqs, mask, return_attention=True)\n",
    "\n",
    "    # Select the attention weights for the specified head\n",
    "    attention_weights = attention_weights[0, head_num].detach().cpu().numpy()\n",
    "\n",
    "    # Plot the attention weights\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(attention_weights, cmap=\"viridis\", xticklabels=sentence.split(), yticklabels=sentence.split())\n",
    "    plt.title(f\"Attention Weights - Layer {layer_num + 1}, Head {head_num + 1}\")\n",
    "    plt.xlabel(\"Key Position\")\n",
    "    plt.ylabel(\"Query Position\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0fe8b886-9d7b-49eb-8a7b-fc9f79b47b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "tensor([   57, 33682, 44884,  5787,  1170, 33785,  1905,    23],\n",
      "       dtype=torch.int32)\n",
      "torch.Size([1, 8, 768])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "model = Aloja(AlojaConfig())\n",
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"./tokenizer/byte-level-bpe.tokenizer.json\")\n",
    "\n",
    "\n",
    "sentence = \"PUTA MERDA DE MODEL.\"\n",
    "layer_num = 0  # Specify the layer number (0-indexed)\n",
    "head_num = 0   # Specify the head number (0-indexed)\n",
    "\n",
    "visualize_attention(model_bad, tokenizer, sentence, layer_num, head_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f63eb53b-77b4-467b-b1d5-17c5f79991fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_loader2.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b875e990-a16b-42e6-ba88-2959f9406af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " de la societat romana, nens i nenes com ells, amb els seus pares, germans, avis.\n",
      "A través de la presentació dels productes podran tocar, olorar, veure i fins i tot tastar una gran varietat de productes natuals i receptes que els portaran a un món força conegut per ells, entenent així la importància de la dieta mediterrània i el seu inici que es remunta més de 2000 anys enrere. No només parlarem d'aquestes aliments crus sinó també els difrents tipus de cocció, els estris necessaris i aliments encara desconeguts per la societat romana.\n",
      "Aquesta és una activitat pensada especialment per l'Educació Primària, tot i que es pot adaptar a l'Educació Secundària i al públic adult, passant a un nivell de comprensió més complexe i amb altres tipus de productes.\n",
      "Per a ampliar la informació no dubteu en posar-vos en contacte amb nosaltres a través de la nostra bústia de correu electrònic: associació@cella-vinaria.comSOLE & HERNANDEZ – Cóm desenvolupar campanyes de màrqueting de continguts per a PIMES?\n",
      "SOLE & HERNANDEZ / Blog / Cóm desenvolupar campanyes de màrqueting de continguts per a PIMES?\n",
      "El màrqueting de continguts o content màrqueting permet establir una relació de confiança entre la PIME i els seus clients actuals o potencials. Si vols captar l'atenció dels teus clients, has oferir continguts de qualitat. Les plataformes que més se solen utilitzar per a estratègies de continguts són el bloc corporatiu, les xarxes socials i altres estratègies en línia.\n",
      "Per tenir èxit en la teva campanya de màrqueting de continguts és imprescindible que aquests siguin molt atractius, summament interessants, útils i / o de qualitat. Per tant, oblida't de continguts excessivament publicitaris o autobombo, ningú vol saber el bo que són els teus productes o els teus serveis, i si ho vol saber, segurament ho consultarà amb tercers que seran més objectius que tu. El client que inverteixi temps en els teus escrits, voldrà llegir temes del seu interès, que l'ajudin o serveixin per a alguna cosa (per tant, pensa sempre en EL QUE VOL LLEGIR EL LECTOR, no el que t'interessi escriure a tu). I recorda, l'autobombo és spam, i si perds un lector potencial serà difícil recuperar-lo.\n",
      "Però, de què escriure?. La resposta és senzilla i complexa a la vegada. Complexa ja que cada empresa haurà de buscar les seves temàtiques d'interès i senzilla ja que cada article que escriguis haurà de respondre a les següents preguntes: aquest escrit resultarà interessant per als meus seguidors?, els aporta informació rellevant?, els ajudarà ?, etc …\n",
      "És interessant que sàpigues que el 70% dels clients de les PIME obtenen informació preliminar de l'empresa, els seus productes o serveis, en primer lloc a Internet i a les seves xarxes socials. Les empreses que aconsegueixen generar informació rellevant per als seus clients potencials mitjançant accions en línia, generen un 55% més de visites a la seva pàgina web corporativa. A més, avui dia, més del 50% de les empreses ja comencen a implementar accions de content màrqueting, i ho estan incorporat en la seva estratègia de marca corporativa.\n",
      "Però el màrqueting de continguts no només consisteix a publicar sense solta ni volta, es requereix de professionals qualificats que coneguin aspectes com: com redactar per a Internet o les xarxes socials, coneixements de posicionament SEO, d'interacció, etc. Has de saber que com millor sigui el posicionament dels articles, més creixerà el nombre de visites a la web i, a més visites, més clients potencials.\n",
      "Els passos a seguir a l'hora d'implementar una bona estratègia de continguts seria:\n",
      "· Analitzar els motius pels quals la teva PIME ha de generar una estratègia de continguts en línia\n",
      "· Analitzar el perfil dels públics a cada xarxa social i la seva vinculació amb la teva PIME\n",
      "· Analitzar els canals que més et convinguin en cada cas: bloc corporatiu, newsletter digital, presentacions corporatives digitals, app's, xarxes socials: Facebook, Twitter, LinkedIn, Youtube, Instagram, etc.\n",
      "· Crear un pla de continguts de qualitat a mida de cada canal i pensant en SEO\n",
      "· Establir un calendari de publicacions per a la teva PIME\n",
      "· Crear una estratègia de comunicació amb influencers sectorials\n",
      "· I finalment, fer un seguiment i avaluació continuada\n",
      "Com es pot veure, el tema del màrqueting de continguts requereix d'una bona dosi de preparació i estratègia preliminar. Estar a les xarxes socials i generar continguts és molt fàcil, però fer-ho bé i enfocat a èxit requereix de molta preparació i professionalitat.\n",
      "Si consideres que podem ajudar-te en les teves estratègies en línia, a Solé & Hernández estem a la teva disposició.Ajuts individualitzats per alumnes amb necessitat específica de suport educatiu per al curs 22-23\n",
      "Benvolgudes famílies,Ja està oberta la convocatòria d'ajuts a alumnes amb necessitat específica de suport educatiu.Disposeu de tota la informació al PDF adjunt.Tot...\n",
      "El passat dijous els nens de P2 van fer la sortida a la granja Can Plana. Una sortida que ens apropa al món rural i als animals.Fomentem el respecte i la cura pels animals, ajudem al pagès... (continua)\n",
      "Sembla que va ser ahir quan entràvem per la porta de l'escola per començar un nou curs però ara ja arriba a la seva fi. Al setembre engegàvem i, una vegada més,... (continua)\n",
      "Quina alegria ens han donat!La biblioteca de Sant Roc ens ha deixat un munt de llibres molt interessants per poder llegir a dins de l'aula durant aquest segon trimestre. L'alumnat de C.M.... (continua)\n",
      "Aquesta setmana passada, entre d'altres cerimònies, vam celebrar la graduació dels mésgrans de la casa. El passat dimecres a la tarda ens vam reunir a l'escola per donarl'enhorabona... (continua)Comitent - Viquipèdia, l'enciclopèdia lliure\n",
      "El comitent és la persona que paga i encarrega a una altra persona (mestres d'obra, artistes, etc.) la realització d'una obra d'art.[1] El comitent pot ser una o diverses persones, o una organització o comunitat. El comitent no té per què ser a més la persona que rep o gaudeix de l'obra d'art, que és el fruitori.[2] Una comitent coneguda va ser, per exemple, a Catalunya, Ermessenda de Carcassona.[2]\n",
      "Per a conèixer plenament una obra d'art, és a dir, incloent el seu valor històric i social, i no només l'estil artístic, cal tenir presents tres elements bàsics: el comitent, l'artista i el fruitori.[2]\n",
      "Els comitents de vegades són mencionats per algun document. Per exemple, en els temps més moderns solen figurar als contractes fets amb l'artista i en èpoques més anteriors poden constar en testaments, documents relacionats amb donacions, en dotalies o actes de consagració.[2]\n",
      "↑ «Comitent». Diccionari de la llengua catalana de l'IEC. Institut d'Estudis Catalans.\n",
      "↑ 2,0 2,1 2,2 2,3 La comtessa de Barcelona, Ermessenda de Carcassona, i la seva contribució als inicis de l'art romànic., pàg. 7, de Antonio Pladevall Font i Antoni Pladevall. Institut d'Estudis Catalans, 2000. ISBN 8472835278Catarroja reforça les seues polítiques mediambientals | Valencia Extra\n",
      "Catarroja està immersa en la campanya de conscienciació per a l'ús del cinqué contenidor, però sense deixar de banda altres campanyes en consonància amb les diverses polítiques mediambientals que, entre altres, tenen l'objectiu de promoure la col·laboració veïnal i millorar les conductes de reciclatge. Per a aquest fi, des de fa unes setmanes es compta amb una tècnica d'educació i control ambiental que serà l'encarregada de gestionar aquestes ambicioses campanyes. Catarroja vol continuar avançant per a aportar el seu granet d'arena a la sostenibilitat i l'economia circular que ens ajuden a la preservació del nostre entorn més pròxim i en general del Planeta.\n",
      "\"Amb el reforç de personal en educació ambiental podrem donar un impuls a les campanyes que tenim previstes des de la regidoria de sostenibilitat per a la població: des de com reciclar o la importància de cuidar el nostre entorn sent d'allò més cívics i col·laboratius en la neteja del nostre poble, passant per incidir en la reducció de residus com a aposta principal. Serà important la seua tasca en la implantació del cinqué contenidor que ja tenim en tota la població i que, després de pocs mesos, estem tenint ja bons resultats\", explica Elisa Gimeno, regidora de sostenibilitat i medi ambient.\n",
      "Una de les novetats que es posaran en marxa a partir d'ara serà la informació a peu de carrer a les persones usuàries de l'ecoparc mòbil que instal·la periòdicament l'Ajuntament de Catarroja enfront de les dependències municipals en Cami Real. Aquest servei de recollida de residus, que posa l'Ajuntament a la disposició de la ciutadania la tercera setmana de cada mes, dilluns, dimarts, dijous i divendres, tindrà el reforç de l'educadora ambiental que aconsellarà en matèria de reciclatge. Per a això, repartirà diferents materials com un calendari de nevera amb els horaris i dates de recollida de residus, un reciclari i un full de mà informatiu del que podem o no llançar en els ecoparcs tan aquest mòbil com en el fixe instal·lat en el polígon de Catarroja.\n",
      "Aquest reforç, en educació ambiental que ve a servir per a poder desenvolupar les campanyes de conscienciació pel medi ambient a Catarroja, compta amb la subvenció de la Conselleria d'Economia, a través d'un pla d'ocupació EMPUJU, completat amb fons propis municipals.La Maria, una gatita de pelatge negre i brillant, es va despertar amb el sol d'or a la cara. Va estirar les potes, va fer un bon esternut i va baixar del llit. L'olor de la truita de patata li va arribar al nas, i amb un ronroneig d'alegria va anar a la cuina.\n",
      "\n",
      "\"Bon dia, Maria!\" va dir la seva mare, la senyora Rosa. \"\n"
     ]
    }
   ],
   "source": [
    "print(enc.decode(a[0][1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "768e572e-be0c-48b0-8237-9b40b79c37fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " la societat romana, nens i nenes com ells, amb els seus pares, germans, avis.\n",
      "A través de la presentació dels productes podran tocar, olorar, veure i fins i tot tastar una gran varietat de productes natuals i receptes que els portaran a un món força conegut per ells, entenent així la importància de la dieta mediterrània i el seu inici que es remunta més de 2000 anys enrere. No només parlarem d'aquestes aliments crus sinó també els difrents tipus de cocció, els estris necessaris i aliments encara desconeguts per la societat romana.\n",
      "Aquesta és una activitat pensada especialment per l'Educació Primària, tot i que es pot adaptar a l'Educació Secundària i al públic adult, passant a un nivell de comprensió més complexe i amb altres tipus de productes.\n",
      "Per a ampliar la informació no dubteu en posar-vos en contacte amb nosaltres a través de la nostra bústia de correu electrònic: associació@cella-vinaria.comSOLE & HERNANDEZ – Cóm desenvolupar campanyes de màrqueting de continguts per a PIMES?\n",
      "SOLE & HERNANDEZ / Blog / Cóm desenvolupar campanyes de màrqueting de continguts per a PIMES?\n",
      "El màrqueting de continguts o content màrqueting permet establir una relació de confiança entre la PIME i els seus clients actuals o potencials. Si vols captar l'atenció dels teus clients, has oferir continguts de qualitat. Les plataformes que més se solen utilitzar per a estratègies de continguts són el bloc corporatiu, les xarxes socials i altres estratègies en línia.\n",
      "Per tenir èxit en la teva campanya de màrqueting de continguts és imprescindible que aquests siguin molt atractius, summament interessants, útils i / o de qualitat. Per tant, oblida't de continguts excessivament publicitaris o autobombo, ningú vol saber el bo que són els teus productes o els teus serveis, i si ho vol saber, segurament ho consultarà amb tercers que seran més objectius que tu. El client que inverteixi temps en els teus escrits, voldrà llegir temes del seu interès, que l'ajudin o serveixin per a alguna cosa (per tant, pensa sempre en EL QUE VOL LLEGIR EL LECTOR, no el que t'interessi escriure a tu). I recorda, l'autobombo és spam, i si perds un lector potencial serà difícil recuperar-lo.\n",
      "Però, de què escriure?. La resposta és senzilla i complexa a la vegada. Complexa ja que cada empresa haurà de buscar les seves temàtiques d'interès i senzilla ja que cada article que escriguis haurà de respondre a les següents preguntes: aquest escrit resultarà interessant per als meus seguidors?, els aporta informació rellevant?, els ajudarà ?, etc …\n",
      "És interessant que sàpigues que el 70% dels clients de les PIME obtenen informació preliminar de l'empresa, els seus productes o serveis, en primer lloc a Internet i a les seves xarxes socials. Les empreses que aconsegueixen generar informació rellevant per als seus clients potencials mitjançant accions en línia, generen un 55% més de visites a la seva pàgina web corporativa. A més, avui dia, més del 50% de les empreses ja comencen a implementar accions de content màrqueting, i ho estan incorporat en la seva estratègia de marca corporativa.\n",
      "Però el màrqueting de continguts no només consisteix a publicar sense solta ni volta, es requereix de professionals qualificats que coneguin aspectes com: com redactar per a Internet o les xarxes socials, coneixements de posicionament SEO, d'interacció, etc. Has de saber que com millor sigui el posicionament dels articles, més creixerà el nombre de visites a la web i, a més visites, més clients potencials.\n",
      "Els passos a seguir a l'hora d'implementar una bona estratègia de continguts seria:\n",
      "· Analitzar els motius pels quals la teva PIME ha de generar una estratègia de continguts en línia\n",
      "· Analitzar el perfil dels públics a cada xarxa social i la seva vinculació amb la teva PIME\n",
      "· Analitzar els canals que més et convinguin en cada cas: bloc corporatiu, newsletter digital, presentacions corporatives digitals, app's, xarxes socials: Facebook, Twitter, LinkedIn, Youtube, Instagram, etc.\n",
      "· Crear un pla de continguts de qualitat a mida de cada canal i pensant en SEO\n",
      "· Establir un calendari de publicacions per a la teva PIME\n",
      "· Crear una estratègia de comunicació amb influencers sectorials\n",
      "· I finalment, fer un seguiment i avaluació continuada\n",
      "Com es pot veure, el tema del màrqueting de continguts requereix d'una bona dosi de preparació i estratègia preliminar. Estar a les xarxes socials i generar continguts és molt fàcil, però fer-ho bé i enfocat a èxit requereix de molta preparació i professionalitat.\n",
      "Si consideres que podem ajudar-te en les teves estratègies en línia, a Solé & Hernández estem a la teva disposició.Ajuts individualitzats per alumnes amb necessitat específica de suport educatiu per al curs 22-23\n",
      "Benvolgudes famílies,Ja està oberta la convocatòria d'ajuts a alumnes amb necessitat específica de suport educatiu.Disposeu de tota la informació al PDF adjunt.Tot...\n",
      "El passat dijous els nens de P2 van fer la sortida a la granja Can Plana. Una sortida que ens apropa al món rural i als animals.Fomentem el respecte i la cura pels animals, ajudem al pagès... (continua)\n",
      "Sembla que va ser ahir quan entràvem per la porta de l'escola per començar un nou curs però ara ja arriba a la seva fi. Al setembre engegàvem i, una vegada més,... (continua)\n",
      "Quina alegria ens han donat!La biblioteca de Sant Roc ens ha deixat un munt de llibres molt interessants per poder llegir a dins de l'aula durant aquest segon trimestre. L'alumnat de C.M.... (continua)\n",
      "Aquesta setmana passada, entre d'altres cerimònies, vam celebrar la graduació dels mésgrans de la casa. El passat dimecres a la tarda ens vam reunir a l'escola per donarl'enhorabona... (continua)Comitent - Viquipèdia, l'enciclopèdia lliure\n",
      "El comitent és la persona que paga i encarrega a una altra persona (mestres d'obra, artistes, etc.) la realització d'una obra d'art.[1] El comitent pot ser una o diverses persones, o una organització o comunitat. El comitent no té per què ser a més la persona que rep o gaudeix de l'obra d'art, que és el fruitori.[2] Una comitent coneguda va ser, per exemple, a Catalunya, Ermessenda de Carcassona.[2]\n",
      "Per a conèixer plenament una obra d'art, és a dir, incloent el seu valor històric i social, i no només l'estil artístic, cal tenir presents tres elements bàsics: el comitent, l'artista i el fruitori.[2]\n",
      "Els comitents de vegades són mencionats per algun document. Per exemple, en els temps més moderns solen figurar als contractes fets amb l'artista i en èpoques més anteriors poden constar en testaments, documents relacionats amb donacions, en dotalies o actes de consagració.[2]\n",
      "↑ «Comitent». Diccionari de la llengua catalana de l'IEC. Institut d'Estudis Catalans.\n",
      "↑ 2,0 2,1 2,2 2,3 La comtessa de Barcelona, Ermessenda de Carcassona, i la seva contribució als inicis de l'art romànic., pàg. 7, de Antonio Pladevall Font i Antoni Pladevall. Institut d'Estudis Catalans, 2000. ISBN 8472835278Catarroja reforça les seues polítiques mediambientals | Valencia Extra\n",
      "Catarroja està immersa en la campanya de conscienciació per a l'ús del cinqué contenidor, però sense deixar de banda altres campanyes en consonància amb les diverses polítiques mediambientals que, entre altres, tenen l'objectiu de promoure la col·laboració veïnal i millorar les conductes de reciclatge. Per a aquest fi, des de fa unes setmanes es compta amb una tècnica d'educació i control ambiental que serà l'encarregada de gestionar aquestes ambicioses campanyes. Catarroja vol continuar avançant per a aportar el seu granet d'arena a la sostenibilitat i l'economia circular que ens ajuden a la preservació del nostre entorn més pròxim i en general del Planeta.\n",
      "\"Amb el reforç de personal en educació ambiental podrem donar un impuls a les campanyes que tenim previstes des de la regidoria de sostenibilitat per a la població: des de com reciclar o la importància de cuidar el nostre entorn sent d'allò més cívics i col·laboratius en la neteja del nostre poble, passant per incidir en la reducció de residus com a aposta principal. Serà important la seua tasca en la implantació del cinqué contenidor que ja tenim en tota la població i que, després de pocs mesos, estem tenint ja bons resultats\", explica Elisa Gimeno, regidora de sostenibilitat i medi ambient.\n",
      "Una de les novetats que es posaran en marxa a partir d'ara serà la informació a peu de carrer a les persones usuàries de l'ecoparc mòbil que instal·la periòdicament l'Ajuntament de Catarroja enfront de les dependències municipals en Cami Real. Aquest servei de recollida de residus, que posa l'Ajuntament a la disposició de la ciutadania la tercera setmana de cada mes, dilluns, dimarts, dijous i divendres, tindrà el reforç de l'educadora ambiental que aconsellarà en matèria de reciclatge. Per a això, repartirà diferents materials com un calendari de nevera amb els horaris i dates de recollida de residus, un reciclari i un full de mà informatiu del que podem o no llançar en els ecoparcs tan aquest mòbil com en el fixe instal·lat en el polígon de Catarroja.\n",
      "Aquest reforç, en educació ambiental que ve a servir per a poder desenvolupar les campanyes de conscienciació pel medi ambient a Catarroja, compta amb la subvenció de la Conselleria d'Economia, a través d'un pla d'ocupació EMPUJU, completat amb fons propis municipals.La Maria, una gatita de pelatge negre i brillant, es va despertar amb el sol d'or a la cara. Va estirar les potes, va fer un bon esternut i va baixar del llit. L'olor de la truita de patata li va arribar al nas, i amb un ronroneig d'alegria va anar a la cuina.\n",
      "\n",
      "\"Bon dia, Maria!\" va dir la seva mare, la senyora Rosa. \"Ja\n"
     ]
    }
   ],
   "source": [
    "print(enc.decode(a[1][1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e56af8b2-9ede-4d3c-95e7-eb10b87eff1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0828 13:55:13.022000 139722774890304 torch/fx/experimental/symbolic_shapes.py:4449] [0/8] xindex is not in var_ranges, defaulting to unknown range.\n",
      "W0828 13:56:12.995000 139722774890304 torch/fx/experimental/symbolic_shapes.py:4449] [0/9] xindex is not in var_ranges, defaulting to unknown range.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: Hola, sóc un model de llenguatge de por qualsevol de fer una sol posar poc de cada més millor què ells tots més més ens més tots més millor que més\n",
      "sample 1: Hola, sóc un model de llenguatge), in una simple sense una bona així una massa possible molts més cada mateix una més més més més més més més baixa té\n",
      "sample 2: Hola, sóc un model de llenguatge, un què menys aigua cert aquests una si molta més si aquests massa més si els més més més més més a aquests o\n",
      "sample 3: Hola, sóc un model de llenguatge per bo una és com més millor totalment què alguna més més tens que més si aquesta bé més millor això si menys persona molt\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "num_return_sequences = 4\n",
    "max_length = 32\n",
    "tokens = list(enc.encode(\"Hola, sóc un model de llenguatge\").ids)\n",
    "tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "xgen = tokens.to(device)\n",
    "sample_rng = torch.Generator(device=device)\n",
    "sample_rng.manual_seed(42)\n",
    "while xgen.size(1) < max_length:\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
    "            logits, loss = model(xgen) # (B, T, vocab_size)\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        ix = torch.multinomial(topk_probs, 1, generator=sample_rng) # (B, 1)\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        xgen = torch.cat((xgen, xcol), dim=1)\n",
    "# print the generated text\n",
    "for i in range(num_return_sequences):\n",
    "    tokens = xgen[i, :max_length].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(f\"sample {i}: {decoded}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
